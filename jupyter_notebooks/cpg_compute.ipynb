{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d38578b-7db1-4ad0-9650-d87e6902949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Many modules are hidden in this stack. Use \"module --show_hidden spider SOFTWARE\" if you are not able to find the required software\n",
      "\n",
      "Inactive Modules:\n",
      "  1) python/3.11.6_cuda\n",
      "\n",
      "Due to MODULEPATH changes, the following have been reloaded:\n",
      "  1) hdf5/1.14.3     2) r/4.3.2\n",
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) cuda/12.2.1 => cuda/12.8.0     3) stack/2024-05 => stack/2024-06\n",
      "  2) gcc/13.2.0 => gcc/12.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module load stack/2024-06 gcc/12.2.0 bedtools2/2.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47402644-7fe7-4970-bcd4-d7a4b35a302c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cluster/home/taekim/stressed_mice/jupyter_notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89ac672-f744-4ebe-aead-6225e83a5456",
   "metadata": {},
   "source": [
    "                        Sample     Median\n",
    "0   Sample_14_CRS_evening_S14_   2.546314\n",
    "0  Sample_15_Ctrl_evening_S15_   3.570246\n",
    "0   Sample_05_Ctrl_morning_S5_   6.184096\n",
    "0   Sample_01_Ctrl_morning_S1_   6.921409\n",
    "0   Sample_16_CRS_evening_S16_   2.879618\n",
    "0  Sample_11_Ctrl_evening_S11_   2.485161\n",
    "0  Sample_13_Ctrl_evening_S13_   2.403964\n",
    "0    Sample_08_CRS_morning_S8_   5.246539\n",
    "0   Sample_20_CRS_evening_S20_  10.633666\n",
    "0   Sample_18_CRS_evening_S18_   4.602043\n",
    "0  Sample_17_Ctrl_evening_S17_   2.929046\n",
    "0    Sample_04_CRS_morning_S4_   6.227455\n",
    "0  Sample_19_Ctrl_evening_S19_   2.545900\n",
    "0   Sample_03_Ctrl_morning_S3_   9.529751\n",
    "0    Sample_02_CRS_morning_S2_   7.151634\n",
    "0   Sample_09_Ctrl_morning_S9_   7.923174\n",
    "0   Sample_10_CRS_morning_S10_   8.815860\n",
    "0    Sample_06_CRS_morning_S6_   7.930738\n",
    "0   Sample_12_CRS_evening_S12_   2.849694\n",
    "0   Sample_07_Ctrl_morning_S7_   4.924262"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14d60d80-fb24-4bd3-8aa2-52c6293aedb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/bedtools2-2.31.0-a4obbslkxntgdx2criopqpwx662gcftq/bin/bedtools getfasta -fi /nfs/nas12.ethz.ch/fs1201/green_groups_let_public/Euler/Navnit/genomes/mouse/GRCm39_NCBI_Bowtie2.fasta -bed /nfs/nas12.ethz.ch/fs1201/green_groups_let_public/Euler/Vakil/mouse_genome_annotation/Genes_Promoters_CpG_islands_for_Tae/allCpG_islands_GRCm39.bed -bedOut > /cluster/scratch/taekim/data_oxidation/cpg_intersect/allCpG_islands.SEQ.bed\n",
      "Command completed successfully\n",
      "Starting processing of samples\n",
      "Processing file: Sample_01_Ctrl_morning_S1_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 12285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/tmp.31808451.taekim/ipykernel_2089473/2859734448.py:161: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_data = pd.concat([all_data, file_data], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Sample_01_Ctrl_morning_S1_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 12493\n",
      "Processing file: Sample_02_CRS_morning_S2_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 14585\n",
      "Processing file: Sample_02_CRS_morning_S2_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 14884\n",
      "Processing file: Sample_03_Ctrl_morning_S3_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 15610\n",
      "Processing file: Sample_03_Ctrl_morning_S3_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 15956\n",
      "Processing file: Sample_04_CRS_morning_S4_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 11335\n",
      "Processing file: Sample_04_CRS_morning_S4_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 10942\n",
      "Processing file: Sample_05_Ctrl_morning_S5_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 9503\n",
      "Processing file: Sample_05_Ctrl_morning_S5_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 9478\n",
      "Processing file: Sample_06_CRS_morning_S6_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 14900\n",
      "Processing file: Sample_06_CRS_morning_S6_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 15030\n",
      "Processing file: Sample_07_Ctrl_morning_S7_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 10559\n",
      "Processing file: Sample_07_Ctrl_morning_S7_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 10344\n",
      "Processing file: Sample_08_CRS_morning_S8_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 11431\n",
      "Processing file: Sample_08_CRS_morning_S8_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 11220\n",
      "Processing file: Sample_09_Ctrl_morning_S9_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 13233\n",
      "Processing file: Sample_09_Ctrl_morning_S9_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 12675\n",
      "Processing file: Sample_10_CRS_morning_S10_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 21012\n",
      "Processing file: Sample_10_CRS_morning_S10_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 20874\n",
      "Processing file: Sample_11_Ctrl_evening_S11_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 4855\n",
      "Processing file: Sample_11_Ctrl_evening_S11_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 4721\n",
      "Processing file: Sample_12_CRS_evening_S12_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 5491\n",
      "Processing file: Sample_12_CRS_evening_S12_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 5343\n",
      "Processing file: Sample_13_Ctrl_evening_S13_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 4099\n",
      "Processing file: Sample_13_Ctrl_evening_S13_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 4030\n",
      "Processing file: Sample_14_CRS_evening_S14_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 4398\n",
      "Processing file: Sample_14_CRS_evening_S14_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 4566\n",
      "Processing file: Sample_15_Ctrl_evening_S15_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 8875\n",
      "Processing file: Sample_15_Ctrl_evening_S15_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 8948\n",
      "Processing file: Sample_16_CRS_evening_S16_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 6135\n",
      "Processing file: Sample_16_CRS_evening_S16_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 6168\n",
      "Processing file: Sample_17_Ctrl_evening_S17_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 4752\n",
      "Processing file: Sample_17_Ctrl_evening_S17_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 4551\n",
      "Processing file: Sample_18_CRS_evening_S18_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 7849\n",
      "Processing file: Sample_18_CRS_evening_S18_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 8224\n",
      "Processing file: Sample_19_Ctrl_evening_S19_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 5179\n",
      "Processing file: Sample_19_Ctrl_evening_S19_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 5507\n",
      "Processing file: Sample_20_CRS_evening_S20_.GRCh38.p13_G_minus_strand.bed\n",
      "  Records: 39199\n",
      "Processing file: Sample_20_CRS_evening_S20_.GRCh38.p13_G_plus_strand.bed\n",
      "  Records: 40085\n",
      "Processing file: allCpG_islands.SEQ.bed\n",
      "  Warning: Could not determine strand for allCpG_islands.SEQ.bed\n",
      "Processing complete! Combined data saved to all_samples_combined_data.csv\n",
      "Total records: 451324\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "\n",
    "# Path with files outputted from bedtools intersect\n",
    "PATH = \"/cluster/scratch/taekim/data_oxidation/cpg_intersect\" \n",
    "OUTPUT_FILE = \"all_samples_combined_data.csv\"\n",
    "GENOME_PATH = \"/nfs/nas12.ethz.ch/fs1201/green_groups_let_public/Euler/Navnit/genomes/mouse/GRCm39_NCBI_Bowtie2.fasta\"\n",
    "# Original path with all CpG coordinates\n",
    "ORG_PATH = \"/nfs/nas12.ethz.ch/fs1201/green_groups_let_public/Euler/Vakil/mouse_genome_annotation/Genes_Promoters_CpG_islands_for_Tae/allCpG_islands_GRCm39.bed\" \n",
    "\n",
    "# Define column names for the input files\n",
    "INPUT_COLUMNS = [\"Chr1\", \"Start1\", \"End1\", \"Value\", \"MAPQ\", \"Chr2\", \"Start2\", \"End2\"]\n",
    "\n",
    "# Define columns for the output file\n",
    "OUTPUT_COLUMNS = [\"id\", \"sample\", \"chromosome\", \"strand\", \"GC_count\", \"damage\", \n",
    "                  \"GC_normalized_damage\", \"median\", \"median_normalized_damage\"]\n",
    "\n",
    "# Define the median values for each sample\n",
    "# Median value for each sample from 100kb bins\n",
    "median_values = {\n",
    "    \"Sample_14_CRS_evening_S14_\": 2.546314,\n",
    "    \"Sample_15_Ctrl_evening_S15_\": 3.570246,\n",
    "    \"Sample_05_Ctrl_morning_S5_\": 6.184096,\n",
    "    \"Sample_01_Ctrl_morning_S1_\": 6.921409,\n",
    "    \"Sample_16_CRS_evening_S16_\": 2.879618,\n",
    "    \"Sample_11_Ctrl_evening_S11_\": 2.485161,\n",
    "    \"Sample_13_Ctrl_evening_S13_\": 2.403964,\n",
    "    \"Sample_08_CRS_morning_S8_\": 5.246539,\n",
    "    \"Sample_20_CRS_evening_S20_\": 10.633666,\n",
    "    \"Sample_18_CRS_evening_S18_\": 4.602043,\n",
    "    \"Sample_17_Ctrl_evening_S17_\": 2.929046,\n",
    "    \"Sample_04_CRS_morning_S4_\": 6.227455,\n",
    "    \"Sample_19_Ctrl_evening_S19_\": 2.545900,\n",
    "    \"Sample_03_Ctrl_morning_S3_\": 9.529751,\n",
    "    \"Sample_02_CRS_morning_S2_\": 7.151634,\n",
    "    \"Sample_09_Ctrl_morning_S9_\": 7.923174,\n",
    "    \"Sample_10_CRS_morning_S10_\": 8.815860,\n",
    "    \"Sample_06_CRS_morning_S6_\": 7.930738,\n",
    "    \"Sample_12_CRS_evening_S12_\": 2.849694,\n",
    "    \"Sample_07_Ctrl_morning_S7_\": 4.924262\n",
    "}\n",
    "\n",
    "def run_bedtools_getfasta(bed_file, output_file, genome_path):\n",
    "    \"\"\"Run bedtools getfasta command to get sequence data for a BED file\"\"\"\n",
    "    command = f\"/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/bedtools2-2.31.0-a4obbslkxntgdx2criopqpwx662gcftq/bin/bedtools getfasta -fi {genome_path} -bed {bed_file} -bedOut > {output_file}\"\n",
    "    print(f\"Running command: {command}\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, check=True, \n",
    "                               stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
    "                               text=True)\n",
    "        print(\"Command completed successfully\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running bedtools: {e}\")\n",
    "        print(f\"STDERR: {e.stderr}\")\n",
    "        return False\n",
    "\n",
    "SEQ_COLUMNS = [\"Chr\", \"Start\", \"End\", \"Seq\"]\n",
    "seq_output_file = os.path.join(PATH, \"allCpG_islands.SEQ.bed\")\n",
    "# Run getfasta with original CpG coordinate file\n",
    "run_bedtools_getfasta(ORG_PATH, seq_output_file, GENOME_PATH)\n",
    "seq_df = pd.read_csv(seq_output_file, sep=\"\\t\", header=None, names=SEQ_COLUMNS)\n",
    "\n",
    "# Create an empty DataFrame for the final output\n",
    "all_data = pd.DataFrame(columns=OUTPUT_COLUMNS)\n",
    "\n",
    "print(\"Starting processing of samples\")\n",
    "\n",
    "# Collect all files for each sample\n",
    "bed_files = glob.glob(os.path.join(PATH, \"*.bed\"))\n",
    "\n",
    "# Process each file\n",
    "for file_path in sorted(bed_files):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"Processing file: {file_name}\")\n",
    "    \n",
    "    # Extract sample name and strand information from the filename\n",
    "    # Example: Sample_01_Ctrl_morning_S1_.GRCh38.p13_G_plus_strand.bed\n",
    "    parts = file_name.split('.')\n",
    "    sample_name = parts[0]  # e.g., Sample_01_Ctrl_morning_S1_\n",
    "    \n",
    "    if \"plus_strand\" in file_name:\n",
    "        strand = \"+\"\n",
    "    elif \"minus_strand\" in file_name:\n",
    "        strand = \"-\"\n",
    "    else:\n",
    "        print(f\"  Warning: Could not determine strand for {file_name}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Define the sequence output file path\n",
    "        \n",
    "        # Read the file\n",
    "        df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=INPUT_COLUMNS)\n",
    "        print(f\"  Records: {len(df)}\")\n",
    "        \n",
    "        # SANITY CHECK 1: Check if Chr1 equals Chr2 for all rows\n",
    "        chr_mismatch = df[df['Chr1'] != df['Chr2']]\n",
    "        if not chr_mismatch.empty:\n",
    "            print(f\"  WARNING: Found {len(chr_mismatch)} rows where Chr1 does not match Chr2\")\n",
    "            print(f\"  First few mismatches: {chr_mismatch[['Chr1', 'Chr2']].head().to_string(index=False)}\")\n",
    "    \n",
    "        # SANITY CHECK 2: Check if there are multiple End2 values for the same Chr1_Start2 combination\n",
    "        # Create the identifier\n",
    "        df['identifier'] = df['Chr1'] + '_' + df['Start2'].astype(str)\n",
    "    \n",
    "        # Group by the identifier and count unique End2 values\n",
    "        end2_counts = df.groupby('identifier')['End2'].nunique()\n",
    "    \n",
    "        # Find identifiers with multiple End2 values\n",
    "        multiple_ends = end2_counts[end2_counts > 1].index.tolist()\n",
    "    \n",
    "        if multiple_ends:\n",
    "            print(f\"  WARNING: Found {len(multiple_ends)} Chr1_Start2 combinations with multiple End2 values\")\n",
    "            print(f\"  First few examples:\")\n",
    "            for idx in multiple_ends[:3]:  # Show first 3 examples\n",
    "                example = df[df['identifier'] == idx][['Chr1', 'Start2', 'End2']]\n",
    "                print(f\"    {idx}: End2 values: {sorted(example['End2'].unique())}\")\n",
    "    \n",
    "        # Create a DataFrame for this file's processed data\n",
    "        file_data = pd.DataFrame()\n",
    "  \n",
    "        # Fill in the known columns\n",
    "        file_data['id'] = df['Chr1'] + '_' + df['Start2'].astype(str)\n",
    "        file_data['sample'] = sample_name\n",
    "        file_data['chromosome'] = df['Chr1']\n",
    "        file_data['strand'] = strand\n",
    "\n",
    "        # Create a unique identifier using Chr_Start format for sequence data\n",
    "        seq_df['region_id'] = seq_df['Chr'] + '_' + seq_df['Start'].astype(str)\n",
    "        # Create a lookup dictionary from seq_df\n",
    "        seq_dict = dict(zip(seq_df['region_id'], seq_df['Seq']))\n",
    "        # Determine which nucleotide to count based on strand\n",
    "        nucleotide = 'G' if strand == '+' else 'C'\n",
    "        # Count the appropriate nucleotides for matching regions\n",
    "        file_data['GC_count'] = file_data['id'].map(lambda region: str(seq_dict.get(region, '')).upper().count(nucleotide) if region in seq_dict else np.nan)\n",
    "\n",
    "        # Calculate the damage by summing up all Value values for each id\n",
    "        damage_dict = df.groupby(df['Chr1'] + '_' + df['Start2'].astype(str))['Value'].sum().to_dict()\n",
    "        file_data['damage'] = file_data['id'].map(damage_dict)\n",
    "    \n",
    "        # Calculate GC normalized damage if GC_count is not zero or NaN\n",
    "        file_data['GC_normalized_damage'] = file_data.apply(lambda row: row['damage'] / row['GC_count'] if row['GC_count'] > 0 else np.nan, axis=1)\n",
    "\n",
    "        if sample_name in median_values:\n",
    "            file_data['median'] = median_values[sample_name]\n",
    "        \n",
    "            # Calculate the median normalized damage\n",
    "            file_data['median_normalized_damage'] = file_data['GC_normalized_damage'] / file_data['median']\n",
    "        else:\n",
    "            print(f\"  Warning: No median value found for sample {sample_name}\")\n",
    "            file_data['median'] = np.nan\n",
    "            file_data['median_normalized_damage'] = np.nan\n",
    "    \n",
    "        # Append this file's data to the all_data DataFrame\n",
    "        all_data = pd.concat([all_data, file_data], ignore_index=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {file_name}: {str(e)}\")\n",
    "        print(f\"  Exception details: {type(e).__name__}: {str(e)}\")\n",
    "\n",
    "# Save the combined data to a CSV file\n",
    "all_data.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Processing complete! Combined data saved to {OUTPUT_FILE}\")\n",
    "print(f\"Total records: {len(all_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117092ae-cb14-4062-b462-3b3b8abd3000",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
