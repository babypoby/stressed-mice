{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd803ba-620b-4080-a055-c41c58da9a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e1295-bfb4-4887-8806-efeaff751f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_two_way_anova(bin_data, factor1_name, factor2_name):\n",
    "    \"\"\"\n",
    "    Perform two-way ANOVA on a single bin's data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    bin_data : pandas.DataFrame\n",
    "        DataFrame with columns for 'measurement', factor1_name, and factor2_name\n",
    "    factor1_name : str\n",
    "        Name of the first factor\n",
    "    factor2_name : str\n",
    "        Name of the second factor\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with p-values and F-values for each factor and interaction\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create the formula for the model\n",
    "        formula = f\"measurement ~ C({factor1_name}) + C({factor2_name}) + C({factor1_name}):C({factor2_name})\"\n",
    "        \n",
    "        # Fit the model (using Type III SS)\n",
    "        model = ols(formula, data=bin_data).fit()\n",
    "        \n",
    "        # Get ANOVA table\n",
    "        anova_table = sm.stats.anova_lm(model, typ=3)\n",
    "        \n",
    "        # Extract results\n",
    "        results = {\n",
    "            'factor1_pvalue': anova_table.loc[f'C({factor1_name})', 'PR(>F)'],\n",
    "            'factor2_pvalue': anova_table.loc[f'C({factor2_name})', 'PR(>F)'],\n",
    "            'interaction_pvalue': anova_table.loc[f'C({factor1_name}):C({factor2_name})', 'PR(>F)'],\n",
    "            'factor1_Fvalue': anova_table.loc[f'C({factor1_name})', 'F'],\n",
    "            'factor2_Fvalue': anova_table.loc[f'C({factor2_name})', 'F'],\n",
    "            'interaction_Fvalue': anova_table.loc[f'C({factor1_name}):C({factor2_name})', 'F']\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Return NaN values if error occurs\n",
    "        return {\n",
    "            'factor1_pvalue': np.nan,\n",
    "            'factor2_pvalue': np.nan,\n",
    "            'interaction_pvalue': np.nan,\n",
    "            'factor1_Fvalue': np.nan,\n",
    "            'factor2_Fvalue': np.nan,\n",
    "            'interaction_Fvalue': np.nan\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1e972-b5e2-4e7b-8555-11ed0f36c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bin(bin_idx, bin_id, bin_data, metadata, factor1_name, factor2_name):\n",
    "    \"\"\"Process a single bin - for parallel processing\"\"\"\n",
    "    # Extract measurements for this bin\n",
    "    bin_values = bin_data.iloc[bin_idx, 1:].values\n",
    "    \n",
    "    # Create DataFrame with measurements and factors\n",
    "    df = pd.DataFrame({\n",
    "        'measurement': bin_values,\n",
    "        factor1_name: metadata[factor1_name].values,\n",
    "        factor2_name: metadata[factor2_name].values\n",
    "    })\n",
    "    \n",
    "    # Perform ANOVA\n",
    "    result = perform_two_way_anova(df, factor1_name, factor2_name)\n",
    "    result['bin_id'] = bin_id\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9995d-3f91-4279-bf05-f7c57d07dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_genomic_bins(data_file, metadata_file, factor1_name, factor2_name, output_prefix, n_cores=None):\n",
    "    \"\"\"\n",
    "    Analyze thousands of genomic bins with two-way ANOVA\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_file : str\n",
    "        Path to CSV file with bin data (first column is bin_id, other columns are samples)\n",
    "    metadata_file : str\n",
    "        Path to CSV file with sample metadata (must have sample_id, factor1_name, and factor2_name columns)\n",
    "    factor1_name : str\n",
    "        Name of the first factor in metadata\n",
    "    factor2_name : str\n",
    "        Name of the second factor in metadata\n",
    "    output_prefix : str\n",
    "        Prefix for output files\n",
    "    n_cores : int, optional\n",
    "        Number of CPU cores to use for parallel processing. If None, uses all available cores - 1\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame with ANOVA results for all bins\n",
    "    \"\"\"\n",
    "    print(\"Reading data...\")\n",
    "    # Read data\n",
    "    data = pd.read_csv(data_file)\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    \n",
    "    # Get bin IDs\n",
    "    bin_ids = data.iloc[:, 0].values\n",
    "    \n",
    "    # Ensure the column names in data match the sample_ids in metadata\n",
    "    data_cols = data.columns[1:]\n",
    "    metadata_samples = metadata['sample_id'].values\n",
    "    \n",
    "    # Check that all data columns are in metadata\n",
    "    missing_cols = set(data_cols) - set(metadata_samples)\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"The following samples in data are missing from metadata: {missing_cols}\")\n",
    "        \n",
    "    # Ensure the order of columns in data matches the order in metadata\n",
    "    # We'll reorder the metadata to match the data\n",
    "    sample_order = {sample: i for i, sample in enumerate(data_cols)}\n",
    "    metadata['data_order'] = metadata['sample_id'].map(sample_order)\n",
    "    metadata = metadata.sort_values('data_order').reset_index(drop=True)\n",
    "    metadata = metadata.drop(columns=['data_order'])\n",
    "    \n",
    "    # Check if factors exist in metadata\n",
    "    if factor1_name not in metadata.columns:\n",
    "        raise ValueError(f\"Factor '{factor1_name}' not found in metadata\")\n",
    "    if factor2_name not in metadata.columns:\n",
    "        raise ValueError(f\"Factor '{factor2_name}' not found in metadata\")\n",
    "    \n",
    "    # Determine number of cores for parallel processing\n",
    "    if n_cores is None:\n",
    "        n_cores = max(1, mp.cpu_count() - 1)  # Leave one core free\n",
    "    \n",
    "    print(f\"Processing {len(bin_ids)} bins using {n_cores} cores...\")\n",
    "    \n",
    "    # Initialize results list\n",
    "    results_list = []\n",
    "    \n",
    "    # Set up parallel processing\n",
    "    with mp.Pool(n_cores) as pool:\n",
    "        # Create a partial function with fixed arguments\n",
    "        func = partial(process_bin, \n",
    "                      bin_data=data, \n",
    "                      metadata=metadata, \n",
    "                      factor1_name=factor1_name, \n",
    "                      factor2_name=factor2_name)\n",
    "        \n",
    "        # Process bins in parallel with progress bar\n",
    "        for result in tqdm(pool.starmap(func, [(i, bin_id) for i, bin_id in enumerate(bin_ids)]), \n",
    "                          total=len(bin_ids)):\n",
    "            results_list.append(result)\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Apply multiple testing correction\n",
    "    for col in ['factor1_pvalue', 'factor2_pvalue', 'interaction_pvalue']:\n",
    "        # Benjamini-Hochberg FDR correction\n",
    "        mask = ~np.isnan(results_df[col])\n",
    "        corrected = np.full(len(results_df), np.nan)\n",
    "        \n",
    "        if mask.sum() > 0:\n",
    "            corrected[mask] = multipletests(results_df.loc[mask, col], method='fdr_bh')[1]\n",
    "            \n",
    "        results_df[f'{col}_adj'] = corrected\n",
    "        \n",
    "        # Add significance flag (True/False)\n",
    "        results_df[f'{col.replace(\"pvalue\", \"significant\")}'] = results_df[f'{col}_adj'] < 0.05\n",
    "    \n",
    "    # Write results to file\n",
    "    results_df.to_csv(f\"{output_prefix}_anova_results.csv\", index=False)\n",
    "    \n",
    "    print(f\"Analysis complete. Found:\")\n",
    "    print(f\"  - {results_df['factor1_significant'].sum()} bins significant for {factor1_name}\")\n",
    "    print(f\"  - {results_df['factor2_significant'].sum()} bins significant for {factor2_name}\")\n",
    "    print(f\"  - {results_df['interaction_significant'].sum()} bins significant for interaction\")\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6d532-b4ed-467d-81ea-4ce61602cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def visualize_anova_results(results_df, factor1_name, factor2_name, output_prefix):\n",
    "    \"\"\"\n",
    "    Create visualizations of ANOVA results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame with ANOVA results from analyze_genomic_bins()\n",
    "    factor1_name : str\n",
    "        Name of the first factor\n",
    "    factor2_name : str\n",
    "        Name of the second factor\n",
    "    output_prefix : str\n",
    "        Prefix for output files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with matplotlib figure objects\n",
    "    \"\"\"\n",
    "    # Create output directory for plots\n",
    "    os.makedirs(f\"{output_prefix}_plots\", exist_ok=True)\n",
    "    \n",
    "    print(\"Creating visualizations...\")\n",
    "    figures = {}\n",
    "    \n",
    "    # 1. Manhattan-like plot of p-values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(range(len(results_df)), -np.log10(results_df['factor1_pvalue']), \n",
    "               alpha=0.5, s=10, label=factor1_name)\n",
    "    plt.scatter(range(len(results_df)), -np.log10(results_df['factor2_pvalue']), \n",
    "               alpha=0.5, s=10, label=factor2_name)\n",
    "    plt.scatter(range(len(results_df)), -np.log10(results_df['interaction_pvalue']), \n",
    "               alpha=0.5, s=10, label='Interaction')\n",
    "    \n",
    "    # Add significance thresholds\n",
    "    plt.axhline(-np.log10(0.05), linestyle='--', color='red', label='p=0.05')\n",
    "    plt.axhline(-np.log10(0.05/len(results_df)), linestyle='--', color='blue', label='Bonferroni')\n",
    "    \n",
    "    plt.xlabel('Genomic Bin Index')\n",
    "    plt.ylabel('-log10(p-value)')\n",
    "    plt.title('Manhattan Plot of Two-way ANOVA p-values')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"{output_prefix}_plots/manhattan_plot.png\", dpi=300)\n",
    "    plt.savefig(f\"{output_prefix}_plots/manhattan_plot.pdf\")\n",
    "    figures['manhattan'] = plt.gcf()\n",
    "    \n",
    "    # 2. Volcano plots for each factor\n",
    "    factor_cols = [\n",
    "        (factor1_name, 'factor1_pvalue', 'factor1_Fvalue', 'factor1_significant'),\n",
    "        (factor2_name, 'factor2_pvalue', 'factor2_Fvalue', 'factor2_significant'),\n",
    "        ('Interaction', 'interaction_pvalue', 'interaction_Fvalue', 'interaction_significant')\n",
    "    ]\n",
    "    \n",
    "    for name, pval_col, fval_col, sig_col in factor_cols:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        \n",
    "        # Create a mask for non-NaN values\n",
    "        mask = ~np.isnan(results_df[pval_col]) & ~np.isnan(results_df[fval_col])\n",
    "        \n",
    "        # Create a scatter plot with color indicating significance\n",
    "        plt.scatter(\n",
    "            results_df.loc[mask, fval_col],\n",
    "            -np.log10(results_df.loc[mask, pval_col]),\n",
    "            c=results_df.loc[mask, sig_col].map({True: 'red', False: 'black'}),\n",
    "            alpha=0.5,\n",
    "            s=15\n",
    "        )\n",
    "        \n",
    "        plt.axhline(-np.log10(0.05), linestyle='--', color='red')\n",
    "        plt.xlabel('F value (effect size)')\n",
    "        plt.ylabel('-log10(p-value)')\n",
    "        plt.title(f'Volcano Plot: {name}')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f\"{output_prefix}_plots/volcano_{name.lower().replace(' ', '_')}.png\", dpi=300)\n",
    "        plt.savefig(f\"{output_prefix}_plots/volcano_{name.lower().replace(' ', '_')}.pdf\")\n",
    "        figures[f'volcano_{name.lower().replace(\" \", \"_\")}'] = plt.gcf()\n",
    "    \n",
    "    # 3. Distribution of p-values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create histograms for each factor\n",
    "    bins = np.linspace(0, 1, 21)  # 20 bins from 0 to 1\n",
    "    \n",
    "    for i, (name, col) in enumerate(zip(\n",
    "        [factor1_name, factor2_name, 'Interaction'],\n",
    "        ['factor1_pvalue', 'factor2_pvalue', 'interaction_pvalue']\n",
    "    )):\n",
    "        # Skip NaN values\n",
    "        p_values = results_df[col].dropna()\n",
    "        if len(p_values) > 0:\n",
    "            plt.hist(p_values, bins=bins, alpha=0.5, label=name)\n",
    "    \n",
    "    plt.xlabel('p-value')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Distribution of p-values')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(f\"{output_prefix}_plots/pvalue_distribution.png\", dpi=300)\n",
    "    plt.savefig(f\"{output_prefix}_plots/pvalue_distribution.pdf\")\n",
    "    figures['pvalue_distribution'] = plt.gcf()\n",
    "    \n",
    "    # 4. Venn diagram of significant results\n",
    "    # Create a summary file with counts\n",
    "    sig_factor1 = results_df['factor1_significant'].sum()\n",
    "    sig_factor2 = results_df['factor2_significant'].sum()\n",
    "    sig_interaction = results_df['interaction_significant'].sum()\n",
    "    \n",
    "    sig_factor1_and_factor2 = (results_df['factor1_significant'] & \n",
    "                             results_df['factor2_significant']).sum()\n",
    "    sig_factor1_and_interaction = (results_df['factor1_significant'] & \n",
    "                                 results_df['interaction_significant']).sum()\n",
    "    sig_factor2_and_interaction = (results_df['factor2_significant'] & \n",
    "                                 results_df['interaction_significant']).sum()\n",
    "    sig_all = (results_df['factor1_significant'] & \n",
    "              results_df['factor2_significant'] & \n",
    "              results_df['interaction_significant']).sum()\n",
    "    \n",
    "    # Create a DataFrame with the counts\n",
    "    venn_summary = pd.DataFrame({\n",
    "        'Category': [\n",
    "            'Total Bins',\n",
    "            f'Significant {factor1_name}',\n",
    "            f'Significant {factor2_name}',\n",
    "            'Significant Interaction',\n",
    "            f'Significant {factor1_name} and {factor2_name}',\n",
    "            f'Significant {factor1_name} and Interaction',\n",
    "            f'Significant {factor2_name} and Interaction',\n",
    "            'Significant in all tests'\n",
    "        ],\n",
    "        'Count': [\n",
    "            len(results_df),\n",
    "            sig_factor1,\n",
    "            sig_factor2,\n",
    "            sig_interaction,\n",
    "            sig_factor1_and_factor2,\n",
    "            sig_factor1_and_interaction,\n",
    "            sig_factor2_and_interaction,\n",
    "            sig_all\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    venn_summary.to_csv(f\"{output_prefix}_venn_summary.csv\", index=False)\n",
    "    \n",
    "    return figures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca8107-ad3c-4bc9-aaac-af278806e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_significant_bins(data_file, metadata_file, results_df, factor1_name, factor2_name, \n",
    "                          output_prefix, max_bins=10):\n",
    "    \"\"\"\n",
    "    Analyze and visualize significant bins\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_file : str\n",
    "        Path to CSV file with bin data\n",
    "    metadata_file : str\n",
    "        Path to CSV file with sample metadata\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame with ANOVA results from analyze_genomic_bins()\n",
    "    factor1_name : str\n",
    "        Name of the first factor\n",
    "    factor2_name : str\n",
    "        Name of the second factor\n",
    "    output_prefix : str\n",
    "        Prefix for output files\n",
    "    max_bins : int, optional\n",
    "        Maximum number of top bins to visualize for each factor\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with DataFrames of top bins for each factor\n",
    "    \"\"\"\n",
    "    print(\"Analyzing significant bins...\")\n",
    "    \n",
    "    # Read data\n",
    "    data = pd.read_csv(data_file)\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    \n",
    "    # Create output directory for bin plots\n",
    "    os.makedirs(f\"{output_prefix}_bin_plots\", exist_ok=True)\n",
    "    \n",
    "    # Get top significant bins for each factor\n",
    "    factor_cols = [\n",
    "        (factor1_name, 'factor1_pvalue', 'factor1_significant'),\n",
    "        (factor2_name, 'factor2_pvalue', 'factor2_significant'),\n",
    "        ('Interaction', 'interaction_pvalue', 'interaction_significant')\n",
    "    ]\n",
    "    \n",
    "    top_bins = {}\n",
    "    \n",
    "    for name, pval_col, sig_col in factor_cols:\n",
    "        # Get significant bins\n",
    "        sig_bins = results_df[results_df[sig_col]].copy()\n",
    "        \n",
    "        # Sort by p-value\n",
    "        sig_bins = sig_bins.sort_values(pval_col)\n",
    "        \n",
    "        # Take top bins\n",
    "        top = sig_bins.head(min(max_bins, len(sig_bins)))\n",
    "        \n",
    "        # Save to file\n",
    "        top.to_csv(f\"{output_prefix}_top_{name.lower().replace(' ', '_')}_bins.csv\", index=False)\n",
    "        \n",
    "        # Store in dictionary\n",
    "        top_bins[f'top_{name.lower().replace(\" \", \"_\")}'] = top\n",
    "        \n",
    "        # Plot each top bin\n",
    "        for i, (_, row) in enumerate(top.iterrows()):\n",
    "            plot_single_bin(data, metadata, row['bin_id'], row, factor1_name, factor2_name, \n",
    "                           f\"{output_prefix}_bin_plots/top_{name.lower().replace(' ', '_')}_{i+1}_{row['bin_id']}\")\n",
    "    \n",
    "    return top_bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445dcdf5-f238-4f41-b799-9904e88291af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_bin(data, metadata, bin_id, stats_row, factor1_name, factor2_name, output_file_prefix):\n",
    "    \"\"\"\n",
    "    Plot a single bin's data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with bin data\n",
    "    metadata : pandas.DataFrame\n",
    "        DataFrame with sample metadata\n",
    "    bin_id : str or int\n",
    "        ID of the bin to plot\n",
    "    stats_row : pandas.Series\n",
    "        Row from results DataFrame with statistics for this bin\n",
    "    factor1_name : str\n",
    "        Name of the first factor\n",
    "    factor2_name : str\n",
    "        Name of the second factor\n",
    "    output_file_prefix : str\n",
    "        Prefix for output file\n",
    "    \"\"\"\n",
    "    # Find the row in the original data corresponding to this bin\n",
    "    bin_row = data[data.iloc[:, 0] == bin_id]\n",
    "    \n",
    "    if bin_row.empty:\n",
    "        print(f\"Warning: Bin {bin_id} not found in data\")\n",
    "        return\n",
    "    \n",
    "    # Extract measurements for this bin\n",
    "    bin_data = pd.DataFrame({\n",
    "        'sample_id': data.columns[1:],\n",
    "        'measurement': bin_row.iloc[0, 1:].values\n",
    "    })\n",
    "    \n",
    "    # Merge with metadata\n",
    "    bin_data = pd.merge(bin_data, metadata, on='sample_id')\n",
    "    \n",
    "    # Convert factors to strings (in case they're numeric)\n",
    "    bin_data[factor1_name] = bin_data[factor1_name].astype(str)\n",
    "    bin_data[factor2_name] = bin_data[factor2_name].astype(str)\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Use seaborn for better visualization\n",
    "    sns.pointplot(data=bin_data, x=factor1_name, y='measurement', hue=factor2_name, \n",
    "                 dodge=True, errorbar=('se', 1), capsize=0.2)\n",
    "    \n",
    "    # Add title and subtitle with p-values\n",
    "    plt.title(f\"Bin: {bin_id}\")\n",
    "    plt.suptitle(\n",
    "        f\"{factor1_name} p = {stats_row['factor1_pvalue']:.3e}, \"\n",
    "        f\"{factor2_name} p = {stats_row['factor2_pvalue']:.3e}, \"\n",
    "        f\"Interaction p = {stats_row['interaction_pvalue']:.3e}\",\n",
    "        y=0.92, fontsize=9\n",
    "    )\n",
    "    \n",
    "    plt.ylabel('Oxidation Level')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f\"{output_file_prefix}.png\", dpi=300)\n",
    "    plt.savefig(f\"{output_file_prefix}.pdf\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09caa77-fe3d-4356-b1a6-1ef391c2080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the entire analysis pipeline\"\"\"\n",
    "    import argparse\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='Perform two-way ANOVA on thousands of genomic bins')\n",
    "    parser.add_argument('--data', required=True, help='CSV file with bin data')\n",
    "    parser.add_argument('--metadata', required=True, help='CSV file with sample metadata')\n",
    "    parser.add_argument('--factor1', required=True, help='Name of the first factor in metadata')\n",
    "    parser.add_argument('--factor2', required=True, help='Name of the second factor in metadata')\n",
    "    parser.add_argument('--output', required=True, help='Prefix for output files')\n",
    "    parser.add_argument('--cores', type=int, default=None, help='Number of CPU cores to use')\n",
    "    parser.add_argument('--max-bins', type=int, default=10, \n",
    "                       help='Maximum number of top bins to visualize for each factor')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Run the analysis\n",
    "    results_df = analyze_genomic_bins(\n",
    "        args.data, args.metadata, args.factor1, args.factor2, args.output, args.cores\n",
    "    )\n",
    "    \n",
    "    # Create visualizations\n",
    "    visualize_anova_results(results_df, args.factor1, args.factor2, args.output)\n",
    "    \n",
    "    # Analyze significant bins\n",
    "    analyze_significant_bins(\n",
    "        args.data, args.metadata, results_df, args.factor1, args.factor2, args.output, args.max_bins\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# Example usage:\n",
    "# python genome_anova.py \\\n",
    "#   --data genomic_bins_measurements.csv \\\n",
    "#   --metadata sample_metadata.csv \\\n",
    "#   --factor1 treatment \\\n",
    "#   --factor2 timepoint \\\n",
    "#   --output oxidation_analysis \\\n",
    "#   --cores 4 \\\n",
    "#   --max-bins 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
